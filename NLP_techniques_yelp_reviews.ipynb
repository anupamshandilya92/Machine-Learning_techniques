{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook I have experimented with few basic NLP techniques on yelp reviews dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "CONTRACTION_MAP = {\n",
    "\"ain't\": \"is not\",\n",
    "\"aren't\": \"are not\",\n",
    "\"can't\": \"cannot\",\n",
    "\"can't've\": \"cannot have\",\n",
    "\"'cause\": \"because\",\n",
    "\"could've\": \"could have\",\n",
    "\"couldn't\": \"could not\",\n",
    "\"couldn't've\": \"could not have\",\n",
    "\"didn't\": \"did not\",\n",
    "\"doesn't\": \"does not\",\n",
    "\"don't\": \"do not\",\n",
    "\"hadn't\": \"had not\",\n",
    "\"hadn't've\": \"had not have\",\n",
    "\"hasn't\": \"has not\",\n",
    "\"haven't\": \"have not\",\n",
    "\"he'd\": \"he would\",\n",
    "\"he'd've\": \"he would have\",\n",
    "\"he'll\": \"he will\",\n",
    "\"he'll've\": \"he he will have\",\n",
    "\"he's\": \"he is\",\n",
    "\"how'd\": \"how did\",\n",
    "\"how'd'y\": \"how do you\",\n",
    "\"how'll\": \"how will\",\n",
    "\"how's\": \"how is\",\n",
    "\"I'd\": \"I would\",\n",
    "\"I'd've\": \"I would have\",\n",
    "\"I'll\": \"I will\",\n",
    "\"I'll've\": \"I will have\",\n",
    "\"I'm\": \"I am\",\n",
    "\"I've\": \"I have\",\n",
    "\"i'd\": \"i would\",\n",
    "\"i'd've\": \"i would have\",\n",
    "\"i'll\": \"i will\",\n",
    "\"i'll've\": \"i will have\",\n",
    "\"i'm\": \"i am\",\n",
    "\"i've\": \"i have\",\n",
    "\"isn't\": \"is not\",\n",
    "\"it'd\": \"it would\",\n",
    "\"it'd've\": \"it would have\",\n",
    "\"it'll\": \"it will\",\n",
    "\"it'll've\": \"it will have\",\n",
    "\"it's\": \"it is\",\n",
    "\"let's\": \"let us\",\n",
    "\"ma'am\": \"madam\",\n",
    "\"mayn't\": \"may not\",\n",
    "\"might've\": \"might have\",\n",
    "\"mightn't\": \"might not\",\n",
    "\"mightn't've\": \"might not have\",\n",
    "\"must've\": \"must have\",\n",
    "\"mustn't\": \"must not\",\n",
    "\"mustn't've\": \"must not have\",\n",
    "\"needn't\": \"need not\",\n",
    "\"needn't've\": \"need not have\",\n",
    "\"o'clock\": \"of the clock\",\n",
    "\"oughtn't\": \"ought not\",\n",
    "\"oughtn't've\": \"ought not have\",\n",
    "\"shan't\": \"shall not\",\n",
    "\"sha'n't\": \"shall not\",\n",
    "\"shan't've\": \"shall not have\",\n",
    "\"she'd\": \"she would\",\n",
    "\"she'd've\": \"she would have\",\n",
    "\"she'll\": \"she will\",\n",
    "\"she'll've\": \"she will have\",\n",
    "\"she's\": \"she is\",\n",
    "\"should've\": \"should have\",\n",
    "\"shouldn't\": \"should not\",\n",
    "\"shouldn't've\": \"should not have\",\n",
    "\"so've\": \"so have\",\n",
    "\"so's\": \"so as\",\n",
    "\"that'd\": \"that would\",\n",
    "\"that'd've\": \"that would have\",\n",
    "\"that's\": \"that is\",\n",
    "\"there'd\": \"there would\",\n",
    "\"there'd've\": \"there would have\",\n",
    "\"there's\": \"there is\",\n",
    "\"they'd\": \"they would\",\n",
    "\"they'd've\": \"they would have\",\n",
    "\"they'll\": \"they will\",\n",
    "\"they'll've\": \"they will have\",\n",
    "\"they're\": \"they are\",\n",
    "\"they've\": \"they have\",\n",
    "\"to've\": \"to have\",\n",
    "\"wasn't\": \"was not\",\n",
    "\"we'd\": \"we would\",\n",
    "\"we'd've\": \"we would have\",\n",
    "\"we'll\": \"we will\",\n",
    "\"we'll've\": \"we will have\",\n",
    "\"we're\": \"we are\",\n",
    "\"we've\": \"we have\",\n",
    "\"weren't\": \"were not\",\n",
    "\"what'll\": \"what will\",\n",
    "\"what'll've\": \"what will have\",\n",
    "\"what're\": \"what are\",\n",
    "\"what's\": \"what is\",\n",
    "\"what've\": \"what have\",\n",
    "\"when's\": \"when is\",\n",
    "\"when've\": \"when have\",\n",
    "\"where'd\": \"where did\",\n",
    "\"where's\": \"where is\",\n",
    "\"where've\": \"where have\",\n",
    "\"who'll\": \"who will\",\n",
    "\"who'll've\": \"who will have\",\n",
    "\"who's\": \"who is\",\n",
    "\"who've\": \"who have\",\n",
    "\"why's\": \"why is\",\n",
    "\"why've\": \"why have\",\n",
    "\"will've\": \"will have\",\n",
    "\"won't\": \"will not\",\n",
    "\"won't've\": \"will not have\",\n",
    "\"would've\": \"would have\",\n",
    "\"wouldn't\": \"would not\",\n",
    "\"wouldn't've\": \"would not have\",\n",
    "\"y'all\": \"you all\",\n",
    "\"y'all'd\": \"you all would\",\n",
    "\"y'all'd've\": \"you all would have\",\n",
    "\"y'all're\": \"you all are\",\n",
    "\"y'all've\": \"you all have\",\n",
    "\"you'd\": \"you would\",\n",
    "\"you'd've\": \"you would have\",\n",
    "\"you'll\": \"you will\",\n",
    "\"you'll've\": \"you will have\",\n",
    "\"you're\": \"you are\",\n",
    "\"you've\": \"you have\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import numpy as np\n",
    "import nltk\n",
    "from nltk.tokenize.toktok import ToktokTokenizer\n",
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "import unicodedata\n",
    "nlp = spacy.load('en_core_web_sm', parse=True, tag=True, entity=True)\n",
    "#nlp_vec = spacy.load('en_vecs', parse = True, tag=True, #entity=True)\n",
    "tokenizer = ToktokTokenizer()\n",
    "stopword_list = nltk.corpus.stopwords.words('english')\n",
    "stopword_list.remove('no')\n",
    "stopword_list.remove('not')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(r\"D:\\Datasets\\NLP\\yelp.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>business_id</th>\n",
       "      <th>date</th>\n",
       "      <th>review_id</th>\n",
       "      <th>stars</th>\n",
       "      <th>text</th>\n",
       "      <th>type</th>\n",
       "      <th>user_id</th>\n",
       "      <th>cool</th>\n",
       "      <th>useful</th>\n",
       "      <th>funny</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9yKzy9PApeiPPOUJEtnvkg</td>\n",
       "      <td>2011-01-26</td>\n",
       "      <td>fWKvX83p0-ka4JS3dc6E5A</td>\n",
       "      <td>5</td>\n",
       "      <td>My wife took me here on my birthday for breakf...</td>\n",
       "      <td>review</td>\n",
       "      <td>rLtl8ZkDX5vH5nAx9C3q5Q</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ZRJwVLyzEJq1VAihDhYiow</td>\n",
       "      <td>2011-07-27</td>\n",
       "      <td>IjZ33sJrzXqU-0X6U8NwyA</td>\n",
       "      <td>5</td>\n",
       "      <td>I have no idea why some people give bad review...</td>\n",
       "      <td>review</td>\n",
       "      <td>0a2KyEL0d3Yb1V6aivbIuQ</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6oRAC4uyJCsJl1X0WZpVSA</td>\n",
       "      <td>2012-06-14</td>\n",
       "      <td>IESLBzqUCLdSzSqm0eCSxQ</td>\n",
       "      <td>4</td>\n",
       "      <td>love the gyro plate. Rice is so good and I als...</td>\n",
       "      <td>review</td>\n",
       "      <td>0hT2KtfLiobPvh6cDC8JQg</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>_1QQZuf4zZOyFCvXc0o6Vg</td>\n",
       "      <td>2010-05-27</td>\n",
       "      <td>G-WvGaISbqqaMHlNnByodA</td>\n",
       "      <td>5</td>\n",
       "      <td>Rosie, Dakota, and I LOVE Chaparral Dog Park!!...</td>\n",
       "      <td>review</td>\n",
       "      <td>uZetl9T0NcROGOyFfughhg</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6ozycU1RpktNG2-1BroVtw</td>\n",
       "      <td>2012-01-05</td>\n",
       "      <td>1uJFq2r5QfJG_6ExMRCaGw</td>\n",
       "      <td>5</td>\n",
       "      <td>General Manager Scott Petello is a good egg!!!...</td>\n",
       "      <td>review</td>\n",
       "      <td>vYmM4KTsC8ZfQBg-j5MWkw</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              business_id        date               review_id  stars  \\\n",
       "0  9yKzy9PApeiPPOUJEtnvkg  2011-01-26  fWKvX83p0-ka4JS3dc6E5A      5   \n",
       "1  ZRJwVLyzEJq1VAihDhYiow  2011-07-27  IjZ33sJrzXqU-0X6U8NwyA      5   \n",
       "2  6oRAC4uyJCsJl1X0WZpVSA  2012-06-14  IESLBzqUCLdSzSqm0eCSxQ      4   \n",
       "3  _1QQZuf4zZOyFCvXc0o6Vg  2010-05-27  G-WvGaISbqqaMHlNnByodA      5   \n",
       "4  6ozycU1RpktNG2-1BroVtw  2012-01-05  1uJFq2r5QfJG_6ExMRCaGw      5   \n",
       "\n",
       "                                                text    type  \\\n",
       "0  My wife took me here on my birthday for breakf...  review   \n",
       "1  I have no idea why some people give bad review...  review   \n",
       "2  love the gyro plate. Rice is so good and I als...  review   \n",
       "3  Rosie, Dakota, and I LOVE Chaparral Dog Park!!...  review   \n",
       "4  General Manager Scott Petello is a good egg!!!...  review   \n",
       "\n",
       "                  user_id  cool  useful  funny  \n",
       "0  rLtl8ZkDX5vH5nAx9C3q5Q     2       5      0  \n",
       "1  0a2KyEL0d3Yb1V6aivbIuQ     0       0      0  \n",
       "2  0hT2KtfLiobPvh6cDC8JQg     0       1      0  \n",
       "3  uZetl9T0NcROGOyFfughhg     1       2      0  \n",
       "4  vYmM4KTsC8ZfQBg-j5MWkw     0       0      0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Util functions for data cleaning\n",
    "1. remove_accented_chars: for removing accents\n",
    "2. expand_contractions: for expanding contractions\n",
    "3. remove_special_characters\n",
    "4. simple_stemmer\n",
    "5. lemmatize_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Some Accented text'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def remove_accented_chars(text):\n",
    "    text = unicodedata.normalize('NFKD', text).encode('ascii', 'ignore').decode('utf-8', 'ignore')\n",
    "    return text\n",
    "\n",
    "remove_accented_chars('Sómě Áccěntěd těxt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'You all cannot expand contractions I would think'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def expand_contractions(text, contraction_mapping=CONTRACTION_MAP):\n",
    "    \n",
    "    contractions_pattern = re.compile('({})'.format('|'.join(contraction_mapping.keys())), \n",
    "                                      flags=re.IGNORECASE|re.DOTALL)\n",
    "    def expand_match(contraction):\n",
    "        match = contraction.group(0)\n",
    "        first_char = match[0]\n",
    "        expanded_contraction = contraction_mapping.get(match)\\\n",
    "                                if contraction_mapping.get(match)\\\n",
    "                                else contraction_mapping.get(match.lower())                       \n",
    "        expanded_contraction = first_char+expanded_contraction[1:]\n",
    "        return expanded_contraction\n",
    "        \n",
    "    expanded_text = contractions_pattern.sub(expand_match, text)\n",
    "    expanded_text = re.sub(\"'\", \"\", expanded_text)\n",
    "    return expanded_text\n",
    "\n",
    "expand_contractions(\"Y'all can't expand contractions I'd think\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Well this was fun What do you think '"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def remove_special_characters(text, remove_digits=False):\n",
    "    pattern = r'[^a-zA-z0-9\\s]' if not remove_digits else r'[^a-zA-z\\s]'\n",
    "    text = re.sub(pattern, '', text)\n",
    "    return text\n",
    "\n",
    "remove_special_characters(\"Well this was fun! What do you think? 123#@!\", \n",
    "                          remove_digits=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'My system keep crash hi crash yesterday, our crash daili'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def simple_stemmer(text):\n",
    "    ps = nltk.porter.PorterStemmer()\n",
    "    text = ' '.join([ps.stem(word) for word in text.split()])\n",
    "    return text\n",
    "\n",
    "simple_stemmer(\"My system keeps crashing his crashed yesterday, ours crashes daily\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'My system keep crash ! his crash yesterday , ours crash daily'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def lemmatize_text(text):\n",
    "    text = nlp(text)\n",
    "    text = ' '.join([word.lemma_ if word.lemma_ != '-PRON-' else word.text for word in text])\n",
    "    return text\n",
    "\n",
    "lemmatize_text(\"My system keeps crashing! his crashed yesterday, ours crashes daily\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "', , stopwords , computer not'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def remove_stopwords(text, is_lower_case=False):\n",
    "    tokens = tokenizer.tokenize(text)\n",
    "    tokens = [token.strip() for token in tokens]\n",
    "    if is_lower_case:\n",
    "        filtered_tokens = [token for token in tokens if token not in stopword_list]\n",
    "    else:\n",
    "        filtered_tokens = [token for token in tokens if token.lower() not in stopword_list]\n",
    "    filtered_text = ' '.join(filtered_tokens)    \n",
    "    return filtered_text\n",
    "\n",
    "remove_stopwords(\"The, and, if are stopwords, computer is not\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning the data using above functions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_corpus(corpus, html_stripping=False, contraction_expansion=True,\n",
    "                     accented_char_removal=True, text_lower_case=True, \n",
    "                     text_lemmatization=True, special_char_removal=True, \n",
    "                     stopword_removal=True, remove_digits=True):\n",
    "    \n",
    "    normalized_corpus = []\n",
    "    # normalize each document in the corpus\n",
    "    for doc in corpus:\n",
    "        # strip HTML\n",
    "        if html_stripping:\n",
    "            doc = strip_html_tags(doc)\n",
    "        # remove accented characters\n",
    "        if accented_char_removal:\n",
    "            doc = remove_accented_chars(doc)\n",
    "        # expand contractions    \n",
    "        if contraction_expansion:\n",
    "            doc = expand_contractions(doc)\n",
    "        # lowercase the text    \n",
    "        if text_lower_case:\n",
    "            doc = doc.lower()\n",
    "        # remove extra newlines\n",
    "        doc = re.sub(r'[\\r|\\n|\\r\\n]+', ' ',doc)\n",
    "        # lemmatize text\n",
    "        if text_lemmatization:\n",
    "            doc = lemmatize_text(doc)\n",
    "        # remove special characters and\\or digits    \n",
    "        if special_char_removal:\n",
    "            # insert spaces between special characters to isolate them    \n",
    "            special_char_pattern = re.compile(r'([{.(-)!}])')\n",
    "            doc = special_char_pattern.sub(\" \\\\1 \", doc)\n",
    "            doc = remove_special_characters(doc, remove_digits=remove_digits)  \n",
    "        # remove extra whitespace\n",
    "        doc = re.sub(' +', ' ', doc)\n",
    "        # remove stopwords\n",
    "        if stopword_removal:\n",
    "            doc = remove_stopwords(doc, is_lower_case=text_lower_case)\n",
    "            \n",
    "        normalized_corpus.append(doc)\n",
    "        \n",
    "    return normalized_corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>business_id</th>\n",
       "      <th>date</th>\n",
       "      <th>review_id</th>\n",
       "      <th>stars</th>\n",
       "      <th>text</th>\n",
       "      <th>type</th>\n",
       "      <th>user_id</th>\n",
       "      <th>cool</th>\n",
       "      <th>useful</th>\n",
       "      <th>funny</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9yKzy9PApeiPPOUJEtnvkg</td>\n",
       "      <td>2011-01-26</td>\n",
       "      <td>fWKvX83p0-ka4JS3dc6E5A</td>\n",
       "      <td>5</td>\n",
       "      <td>My wife took me here on my birthday for breakf...</td>\n",
       "      <td>review</td>\n",
       "      <td>rLtl8ZkDX5vH5nAx9C3q5Q</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ZRJwVLyzEJq1VAihDhYiow</td>\n",
       "      <td>2011-07-27</td>\n",
       "      <td>IjZ33sJrzXqU-0X6U8NwyA</td>\n",
       "      <td>5</td>\n",
       "      <td>I have no idea why some people give bad review...</td>\n",
       "      <td>review</td>\n",
       "      <td>0a2KyEL0d3Yb1V6aivbIuQ</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6oRAC4uyJCsJl1X0WZpVSA</td>\n",
       "      <td>2012-06-14</td>\n",
       "      <td>IESLBzqUCLdSzSqm0eCSxQ</td>\n",
       "      <td>4</td>\n",
       "      <td>love the gyro plate. Rice is so good and I als...</td>\n",
       "      <td>review</td>\n",
       "      <td>0hT2KtfLiobPvh6cDC8JQg</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>_1QQZuf4zZOyFCvXc0o6Vg</td>\n",
       "      <td>2010-05-27</td>\n",
       "      <td>G-WvGaISbqqaMHlNnByodA</td>\n",
       "      <td>5</td>\n",
       "      <td>Rosie, Dakota, and I LOVE Chaparral Dog Park!!...</td>\n",
       "      <td>review</td>\n",
       "      <td>uZetl9T0NcROGOyFfughhg</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6ozycU1RpktNG2-1BroVtw</td>\n",
       "      <td>2012-01-05</td>\n",
       "      <td>1uJFq2r5QfJG_6ExMRCaGw</td>\n",
       "      <td>5</td>\n",
       "      <td>General Manager Scott Petello is a good egg!!!...</td>\n",
       "      <td>review</td>\n",
       "      <td>vYmM4KTsC8ZfQBg-j5MWkw</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              business_id        date               review_id  stars  \\\n",
       "0  9yKzy9PApeiPPOUJEtnvkg  2011-01-26  fWKvX83p0-ka4JS3dc6E5A      5   \n",
       "1  ZRJwVLyzEJq1VAihDhYiow  2011-07-27  IjZ33sJrzXqU-0X6U8NwyA      5   \n",
       "2  6oRAC4uyJCsJl1X0WZpVSA  2012-06-14  IESLBzqUCLdSzSqm0eCSxQ      4   \n",
       "3  _1QQZuf4zZOyFCvXc0o6Vg  2010-05-27  G-WvGaISbqqaMHlNnByodA      5   \n",
       "4  6ozycU1RpktNG2-1BroVtw  2012-01-05  1uJFq2r5QfJG_6ExMRCaGw      5   \n",
       "\n",
       "                                                text    type  \\\n",
       "0  My wife took me here on my birthday for breakf...  review   \n",
       "1  I have no idea why some people give bad review...  review   \n",
       "2  love the gyro plate. Rice is so good and I als...  review   \n",
       "3  Rosie, Dakota, and I LOVE Chaparral Dog Park!!...  review   \n",
       "4  General Manager Scott Petello is a good egg!!!...  review   \n",
       "\n",
       "                  user_id  cool  useful  funny  \n",
       "0  rLtl8ZkDX5vH5nAx9C3q5Q     2       5      0  \n",
       "1  0a2KyEL0d3Yb1V6aivbIuQ     0       0      0  \n",
       "2  0hT2KtfLiobPvh6cDC8JQg     0       1      0  \n",
       "3  uZetl9T0NcROGOyFfughhg     1       2      0  \n",
       "4  vYmM4KTsC8ZfQBg-j5MWkw     0       0      0  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': 'I have no idea why some people give bad reviews about this place. It goes to show you, you can please everyone. They are probably griping about something that their own fault...there are many people like that.\\n\\nIn any case, my friend and I arrived at about 5:50 PM this past Sunday. It was pretty crowded, more than I thought for a Sunday evening and thought we would have to wait forever to get a seat but they said we\\'ll be seated when the girl comes back from seating someone else. We were seated at 5:52 and the waiter came and got our drink orders. Everyone was very pleasant from the host that seated us to the waiter to the server. The prices were very good as well. We placed our orders once we decided what we wanted at 6:02. We shared the baked spaghetti calzone and the small \"Here\\'s The Beef\" pizza so we can both try them. The calzone was huge and we got the smallest one (personal) and got the small 11\" pizza. Both were awesome! My friend liked the pizza better and I liked the calzone better. The calzone does have a sweetish sauce but that\\'s how I like my sauce!\\n\\nWe had to box part of the pizza to take it home and we were out the door by 6:42. So, everything was great and not like these bad reviewers. That goes to show you that  you have to try these things yourself because all these bad reviewers have some serious issues.',\n",
       " 'clean_text': 'no idea people give bad review place go show please everyone probably gripe something fault many people like case friend arrive pm past sunday pretty crowded think sunday evening think would wait forever get seat say seat girl come back seat someone else seat waiter come get drink order everyone pleasant host seat us waiter server price good well place order decide want share bake spaghetti calzone small beef pizza try calzone huge get small one personal get small pizza awesome friend like pizza better like calzone better calzone sweetish sauce like sauce box part pizza take home door everything great not like bad reviewer go show try thing bad reviewer serious issue'}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# pre-process text and store the same\n",
    "data['clean_text'] = normalize_corpus(data['text'])\n",
    "norm_corpus = list(data['clean_text'])\n",
    "\n",
    "# show a sample news article\n",
    "data.iloc[1][['text', 'clean_text']].to_dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Techniques experimented with:\n",
    "1. NER using pretrained model en_core_web_sm from spacy\n",
    "2. Tfidf - sklearn\n",
    "3. word2vec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "named_entities = []\n",
    "for sentence in data['clean_text']:\n",
    "    temp_entity_name = ''\n",
    "    temp_named_entity = None\n",
    "    sentence = nlp(sentence)\n",
    "    for word in sentence:\n",
    "        term = word.text \n",
    "        tag = word.ent_type_\n",
    "        if tag:\n",
    "            temp_entity_name = ' '.join([temp_entity_name, term]).strip()\n",
    "            temp_named_entity = (temp_entity_name, tag)\n",
    "        else:\n",
    "            if temp_named_entity:\n",
    "                named_entities.append(temp_named_entity)\n",
    "                temp_entity_name = ''\n",
    "                temp_named_entity = None\n",
    "\n",
    "entity_frame = pd.DataFrame(named_entities, \n",
    "                            columns=['Entity Name', 'Entity Type'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Entity Name</th>\n",
       "      <td>one</td>\n",
       "      <td>first</td>\n",
       "      <td>two</td>\n",
       "      <td>hour</td>\n",
       "      <td>mexican</td>\n",
       "      <td>us</td>\n",
       "      <td>three</td>\n",
       "      <td>half</td>\n",
       "      <td>second</td>\n",
       "      <td>today</td>\n",
       "      <td>thai</td>\n",
       "      <td>chinese</td>\n",
       "      <td>four</td>\n",
       "      <td>arizona</td>\n",
       "      <td>italian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Entity Type</th>\n",
       "      <td>CARDINAL</td>\n",
       "      <td>ORDINAL</td>\n",
       "      <td>CARDINAL</td>\n",
       "      <td>TIME</td>\n",
       "      <td>NORP</td>\n",
       "      <td>GPE</td>\n",
       "      <td>CARDINAL</td>\n",
       "      <td>CARDINAL</td>\n",
       "      <td>ORDINAL</td>\n",
       "      <td>DATE</td>\n",
       "      <td>NORP</td>\n",
       "      <td>NORP</td>\n",
       "      <td>CARDINAL</td>\n",
       "      <td>GPE</td>\n",
       "      <td>NORP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Frequency</th>\n",
       "      <td>2760</td>\n",
       "      <td>1051</td>\n",
       "      <td>1006</td>\n",
       "      <td>473</td>\n",
       "      <td>438</td>\n",
       "      <td>368</td>\n",
       "      <td>361</td>\n",
       "      <td>322</td>\n",
       "      <td>317</td>\n",
       "      <td>286</td>\n",
       "      <td>271</td>\n",
       "      <td>258</td>\n",
       "      <td>243</td>\n",
       "      <td>233</td>\n",
       "      <td>219</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    0        1         2     3        4    5         6  \\\n",
       "Entity Name       one    first       two  hour  mexican   us     three   \n",
       "Entity Type  CARDINAL  ORDINAL  CARDINAL  TIME     NORP  GPE  CARDINAL   \n",
       "Frequency        2760     1051      1006   473      438  368       361   \n",
       "\n",
       "                    7        8      9    10       11        12       13  \\\n",
       "Entity Name      half   second  today  thai  chinese      four  arizona   \n",
       "Entity Type  CARDINAL  ORDINAL   DATE  NORP     NORP  CARDINAL      GPE   \n",
       "Frequency         322      317    286   271      258       243      233   \n",
       "\n",
       "                  14  \n",
       "Entity Name  italian  \n",
       "Entity Type     NORP  \n",
       "Frequency        219  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get the top named entities\n",
    "top_entities = (entity_frame.groupby(by=['Entity Name', 'Entity Type'])\n",
    "                           .size()\n",
    "                           .sort_values(ascending=False)\n",
    "                           .reset_index().rename(columns={0 : 'Frequency'}))\n",
    "top_entities.T.iloc[:,:15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Entity Type</th>\n",
       "      <td>PERSON</td>\n",
       "      <td>CARDINAL</td>\n",
       "      <td>ORG</td>\n",
       "      <td>NORP</td>\n",
       "      <td>DATE</td>\n",
       "      <td>GPE</td>\n",
       "      <td>TIME</td>\n",
       "      <td>ORDINAL</td>\n",
       "      <td>LOC</td>\n",
       "      <td>FAC</td>\n",
       "      <td>PRODUCT</td>\n",
       "      <td>EVENT</td>\n",
       "      <td>QUANTITY</td>\n",
       "      <td>LANGUAGE</td>\n",
       "      <td>MONEY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Frequency</th>\n",
       "      <td>7449</td>\n",
       "      <td>5519</td>\n",
       "      <td>4651</td>\n",
       "      <td>3680</td>\n",
       "      <td>3522</td>\n",
       "      <td>3370</td>\n",
       "      <td>2919</td>\n",
       "      <td>1528</td>\n",
       "      <td>571</td>\n",
       "      <td>456</td>\n",
       "      <td>223</td>\n",
       "      <td>118</td>\n",
       "      <td>109</td>\n",
       "      <td>93</td>\n",
       "      <td>67</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  0         1     2     3     4     5     6        7    8  \\\n",
       "Entity Type  PERSON  CARDINAL   ORG  NORP  DATE   GPE  TIME  ORDINAL  LOC   \n",
       "Frequency      7449      5519  4651  3680  3522  3370  2919     1528  571   \n",
       "\n",
       "               9       10     11        12        13     14  \n",
       "Entity Type  FAC  PRODUCT  EVENT  QUANTITY  LANGUAGE  MONEY  \n",
       "Frequency    456      223    118       109        93     67  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get the top named entity types\n",
    "top_entities = (entity_frame.groupby(by=['Entity Type'])\n",
    "                           .size()\n",
    "                           .sort_values(ascending=False)\n",
    "                           .reset_index().rename(columns={0 : 'Frequency'}))\n",
    "top_entities.T.iloc[:,:15]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For list of annotation schemes :\n",
    "https://spacy.io/api/annotation#named-entities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tf-Idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>aa</th>\n",
       "      <th>aaa</th>\n",
       "      <th>aaaaaalright</th>\n",
       "      <th>aaaamaze</th>\n",
       "      <th>aaammmazze</th>\n",
       "      <th>aaand</th>\n",
       "      <th>aah</th>\n",
       "      <th>aand</th>\n",
       "      <th>aaron</th>\n",
       "      <th>aarp</th>\n",
       "      <th>...</th>\n",
       "      <th>zupa</th>\n",
       "      <th>zupas</th>\n",
       "      <th>zur</th>\n",
       "      <th>zuzu</th>\n",
       "      <th>zuzus</th>\n",
       "      <th>zweigel</th>\n",
       "      <th>zwiebel</th>\n",
       "      <th>zy</th>\n",
       "      <th>zze</th>\n",
       "      <th>zzzzzzzzzzzzzzzzz</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 23567 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       aa  aaa  aaaaaalright  aaaamaze  aaammmazze  aaand  aah  aand  aaron  \\\n",
       "0     0.0  0.0           0.0       0.0         0.0    0.0  0.0   0.0    0.0   \n",
       "1     0.0  0.0           0.0       0.0         0.0    0.0  0.0   0.0    0.0   \n",
       "2     0.0  0.0           0.0       0.0         0.0    0.0  0.0   0.0    0.0   \n",
       "3     0.0  0.0           0.0       0.0         0.0    0.0  0.0   0.0    0.0   \n",
       "4     0.0  0.0           0.0       0.0         0.0    0.0  0.0   0.0    0.0   \n",
       "...   ...  ...           ...       ...         ...    ...  ...   ...    ...   \n",
       "9995  0.0  0.0           0.0       0.0         0.0    0.0  0.0   0.0    0.0   \n",
       "9996  0.0  0.0           0.0       0.0         0.0    0.0  0.0   0.0    0.0   \n",
       "9997  0.0  0.0           0.0       0.0         0.0    0.0  0.0   0.0    0.0   \n",
       "9998  0.0  0.0           0.0       0.0         0.0    0.0  0.0   0.0    0.0   \n",
       "9999  0.0  0.0           0.0       0.0         0.0    0.0  0.0   0.0    0.0   \n",
       "\n",
       "      aarp  ...  zupa  zupas  zur  zuzu  zuzus  zweigel  zwiebel   zy  zze  \\\n",
       "0      0.0  ...   0.0    0.0  0.0   0.0    0.0      0.0      0.0  0.0  0.0   \n",
       "1      0.0  ...   0.0    0.0  0.0   0.0    0.0      0.0      0.0  0.0  0.0   \n",
       "2      0.0  ...   0.0    0.0  0.0   0.0    0.0      0.0      0.0  0.0  0.0   \n",
       "3      0.0  ...   0.0    0.0  0.0   0.0    0.0      0.0      0.0  0.0  0.0   \n",
       "4      0.0  ...   0.0    0.0  0.0   0.0    0.0      0.0      0.0  0.0  0.0   \n",
       "...    ...  ...   ...    ...  ...   ...    ...      ...      ...  ...  ...   \n",
       "9995   0.0  ...   0.0    0.0  0.0   0.0    0.0      0.0      0.0  0.0  0.0   \n",
       "9996   0.0  ...   0.0    0.0  0.0   0.0    0.0      0.0      0.0  0.0  0.0   \n",
       "9997   0.0  ...   0.0    0.0  0.0   0.0    0.0      0.0      0.0  0.0  0.0   \n",
       "9998   0.0  ...   0.0    0.0  0.0   0.0    0.0      0.0      0.0  0.0  0.0   \n",
       "9999   0.0  ...   0.0    0.0  0.0   0.0    0.0      0.0      0.0  0.0  0.0   \n",
       "\n",
       "      zzzzzzzzzzzzzzzzz  \n",
       "0                   0.0  \n",
       "1                   0.0  \n",
       "2                   0.0  \n",
       "3                   0.0  \n",
       "4                   0.0  \n",
       "...                 ...  \n",
       "9995                0.0  \n",
       "9996                0.0  \n",
       "9997                0.0  \n",
       "9998                0.0  \n",
       "9999                0.0  \n",
       "\n",
       "[10000 rows x 23567 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "corpus = list(data['clean_text'])\n",
    "tv = TfidfVectorizer(min_df=0., max_df=1., use_idf=True)\n",
    "tv_matrix = tv.fit_transform(corpus)\n",
    "tv_matrix = tv_matrix.toarray()\n",
    "\n",
    "vocab = tv.get_feature_names()\n",
    "pd.DataFrame(np.round(tv_matrix, 2), columns=vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>9990</th>\n",
       "      <th>9991</th>\n",
       "      <th>9992</th>\n",
       "      <th>9993</th>\n",
       "      <th>9994</th>\n",
       "      <th>9995</th>\n",
       "      <th>9996</th>\n",
       "      <th>9997</th>\n",
       "      <th>9998</th>\n",
       "      <th>9999</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.069024</td>\n",
       "      <td>0.010467</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.015261</td>\n",
       "      <td>0.094788</td>\n",
       "      <td>0.053360</td>\n",
       "      <td>0.011594</td>\n",
       "      <td>0.073810</td>\n",
       "      <td>0.024861</td>\n",
       "      <td>...</td>\n",
       "      <td>0.033307</td>\n",
       "      <td>0.031627</td>\n",
       "      <td>0.053915</td>\n",
       "      <td>0.060268</td>\n",
       "      <td>0.049628</td>\n",
       "      <td>0.046687</td>\n",
       "      <td>0.064000</td>\n",
       "      <td>0.038272</td>\n",
       "      <td>0.016123</td>\n",
       "      <td>0.065352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.069024</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.003733</td>\n",
       "      <td>0.005350</td>\n",
       "      <td>0.054641</td>\n",
       "      <td>0.105227</td>\n",
       "      <td>0.043360</td>\n",
       "      <td>0.017335</td>\n",
       "      <td>0.061418</td>\n",
       "      <td>0.051946</td>\n",
       "      <td>...</td>\n",
       "      <td>0.030553</td>\n",
       "      <td>0.008493</td>\n",
       "      <td>0.061438</td>\n",
       "      <td>0.084784</td>\n",
       "      <td>0.094633</td>\n",
       "      <td>0.214016</td>\n",
       "      <td>0.036598</td>\n",
       "      <td>0.038841</td>\n",
       "      <td>0.060374</td>\n",
       "      <td>0.098484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.010467</td>\n",
       "      <td>0.003733</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.011124</td>\n",
       "      <td>0.005729</td>\n",
       "      <td>0.012205</td>\n",
       "      <td>0.019046</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.127144</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.019261</td>\n",
       "      <td>0.033504</td>\n",
       "      <td>0.005383</td>\n",
       "      <td>0.017865</td>\n",
       "      <td>0.008717</td>\n",
       "      <td>0.015991</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.005350</td>\n",
       "      <td>0.011124</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.008489</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.003785</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.011340</td>\n",
       "      <td>0.060342</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.069234</td>\n",
       "      <td>0.007410</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.003266</td>\n",
       "      <td>0.022640</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.015261</td>\n",
       "      <td>0.054641</td>\n",
       "      <td>0.005729</td>\n",
       "      <td>0.008489</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.016823</td>\n",
       "      <td>0.012748</td>\n",
       "      <td>0.021454</td>\n",
       "      <td>0.025971</td>\n",
       "      <td>0.003840</td>\n",
       "      <td>...</td>\n",
       "      <td>0.010323</td>\n",
       "      <td>0.023018</td>\n",
       "      <td>0.044657</td>\n",
       "      <td>0.017865</td>\n",
       "      <td>0.029387</td>\n",
       "      <td>0.009355</td>\n",
       "      <td>0.028719</td>\n",
       "      <td>0.019008</td>\n",
       "      <td>0.035739</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>0.046687</td>\n",
       "      <td>0.214016</td>\n",
       "      <td>0.017865</td>\n",
       "      <td>0.007410</td>\n",
       "      <td>0.009355</td>\n",
       "      <td>0.077526</td>\n",
       "      <td>0.030959</td>\n",
       "      <td>0.031844</td>\n",
       "      <td>0.006497</td>\n",
       "      <td>0.008813</td>\n",
       "      <td>...</td>\n",
       "      <td>0.024595</td>\n",
       "      <td>0.015726</td>\n",
       "      <td>0.020010</td>\n",
       "      <td>0.045548</td>\n",
       "      <td>0.029424</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.018510</td>\n",
       "      <td>0.022399</td>\n",
       "      <td>0.014778</td>\n",
       "      <td>0.052425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>0.064000</td>\n",
       "      <td>0.036598</td>\n",
       "      <td>0.008717</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.028719</td>\n",
       "      <td>0.058027</td>\n",
       "      <td>0.047275</td>\n",
       "      <td>0.053236</td>\n",
       "      <td>0.062013</td>\n",
       "      <td>0.023624</td>\n",
       "      <td>...</td>\n",
       "      <td>0.039709</td>\n",
       "      <td>0.044919</td>\n",
       "      <td>0.038928</td>\n",
       "      <td>0.077912</td>\n",
       "      <td>0.030953</td>\n",
       "      <td>0.018510</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.043456</td>\n",
       "      <td>0.034188</td>\n",
       "      <td>0.070419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>0.038272</td>\n",
       "      <td>0.038841</td>\n",
       "      <td>0.015991</td>\n",
       "      <td>0.003266</td>\n",
       "      <td>0.019008</td>\n",
       "      <td>0.110931</td>\n",
       "      <td>0.050239</td>\n",
       "      <td>0.025070</td>\n",
       "      <td>0.027943</td>\n",
       "      <td>0.005815</td>\n",
       "      <td>...</td>\n",
       "      <td>0.042084</td>\n",
       "      <td>0.022923</td>\n",
       "      <td>0.045843</td>\n",
       "      <td>0.060783</td>\n",
       "      <td>0.048744</td>\n",
       "      <td>0.022399</td>\n",
       "      <td>0.043456</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.018851</td>\n",
       "      <td>0.015966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>0.016123</td>\n",
       "      <td>0.060374</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.022640</td>\n",
       "      <td>0.035739</td>\n",
       "      <td>0.033987</td>\n",
       "      <td>0.028185</td>\n",
       "      <td>0.020678</td>\n",
       "      <td>0.031558</td>\n",
       "      <td>0.031352</td>\n",
       "      <td>...</td>\n",
       "      <td>0.024265</td>\n",
       "      <td>0.006067</td>\n",
       "      <td>0.071588</td>\n",
       "      <td>0.055446</td>\n",
       "      <td>0.057314</td>\n",
       "      <td>0.014778</td>\n",
       "      <td>0.034188</td>\n",
       "      <td>0.018851</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.015308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>0.065352</td>\n",
       "      <td>0.098484</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.045442</td>\n",
       "      <td>0.014231</td>\n",
       "      <td>0.005939</td>\n",
       "      <td>0.015310</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.035083</td>\n",
       "      <td>0.021012</td>\n",
       "      <td>0.016971</td>\n",
       "      <td>0.029783</td>\n",
       "      <td>0.019842</td>\n",
       "      <td>0.052425</td>\n",
       "      <td>0.070419</td>\n",
       "      <td>0.015966</td>\n",
       "      <td>0.015308</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 10000 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2         3         4         5         6     \\\n",
       "0     1.000000  0.069024  0.010467  0.000000  0.015261  0.094788  0.053360   \n",
       "1     0.069024  1.000000  0.003733  0.005350  0.054641  0.105227  0.043360   \n",
       "2     0.010467  0.003733  1.000000  0.011124  0.005729  0.012205  0.019046   \n",
       "3     0.000000  0.005350  0.011124  1.000000  0.008489  0.000000  0.003785   \n",
       "4     0.015261  0.054641  0.005729  0.008489  1.000000  0.016823  0.012748   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "9995  0.046687  0.214016  0.017865  0.007410  0.009355  0.077526  0.030959   \n",
       "9996  0.064000  0.036598  0.008717  0.000000  0.028719  0.058027  0.047275   \n",
       "9997  0.038272  0.038841  0.015991  0.003266  0.019008  0.110931  0.050239   \n",
       "9998  0.016123  0.060374  0.000000  0.022640  0.035739  0.033987  0.028185   \n",
       "9999  0.065352  0.098484  0.000000  0.000000  0.000000  0.045442  0.014231   \n",
       "\n",
       "          7         8         9     ...      9990      9991      9992  \\\n",
       "0     0.011594  0.073810  0.024861  ...  0.033307  0.031627  0.053915   \n",
       "1     0.017335  0.061418  0.051946  ...  0.030553  0.008493  0.061438   \n",
       "2     0.000000  0.000000  0.000000  ...  0.127144  0.000000  0.019261   \n",
       "3     0.000000  0.000000  0.000000  ...  0.000000  0.011340  0.060342   \n",
       "4     0.021454  0.025971  0.003840  ...  0.010323  0.023018  0.044657   \n",
       "...        ...       ...       ...  ...       ...       ...       ...   \n",
       "9995  0.031844  0.006497  0.008813  ...  0.024595  0.015726  0.020010   \n",
       "9996  0.053236  0.062013  0.023624  ...  0.039709  0.044919  0.038928   \n",
       "9997  0.025070  0.027943  0.005815  ...  0.042084  0.022923  0.045843   \n",
       "9998  0.020678  0.031558  0.031352  ...  0.024265  0.006067  0.071588   \n",
       "9999  0.005939  0.015310  0.000000  ...  0.035083  0.021012  0.016971   \n",
       "\n",
       "          9993      9994      9995      9996      9997      9998      9999  \n",
       "0     0.060268  0.049628  0.046687  0.064000  0.038272  0.016123  0.065352  \n",
       "1     0.084784  0.094633  0.214016  0.036598  0.038841  0.060374  0.098484  \n",
       "2     0.033504  0.005383  0.017865  0.008717  0.015991  0.000000  0.000000  \n",
       "3     0.000000  0.069234  0.007410  0.000000  0.003266  0.022640  0.000000  \n",
       "4     0.017865  0.029387  0.009355  0.028719  0.019008  0.035739  0.000000  \n",
       "...        ...       ...       ...       ...       ...       ...       ...  \n",
       "9995  0.045548  0.029424  1.000000  0.018510  0.022399  0.014778  0.052425  \n",
       "9996  0.077912  0.030953  0.018510  1.000000  0.043456  0.034188  0.070419  \n",
       "9997  0.060783  0.048744  0.022399  0.043456  1.000000  0.018851  0.015966  \n",
       "9998  0.055446  0.057314  0.014778  0.034188  0.018851  1.000000  0.015308  \n",
       "9999  0.029783  0.019842  0.052425  0.070419  0.015966  0.015308  1.000000  \n",
       "\n",
       "[10000 rows x 10000 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "similarity_matrix = cosine_similarity(tv_matrix)\n",
    "similarity_df = pd.DataFrame(similarity_matrix)\n",
    "similarity_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import word2vec\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'god': ['goodness',\n",
       "  'spudnut',\n",
       "  'onward',\n",
       "  'fertility',\n",
       "  'compeopletysoncrosbie'],\n",
       " 'jesus': ['christ', 'architectural', 'ornamental', 'war', 'oprah'],\n",
       " 'abundance': ['fixable', 'frenetic', 'redecorate', 'commence', 'bo'],\n",
       " 'apache': ['mustachio', 'blvd', 'junction', 'pursue', 'university'],\n",
       " 'abbreviate': ['salute', 'aknowledge', 'stepper', 'ltf', 'used'],\n",
       " 'anyway': ['nerd', 'fck', 'kill', 'motivating', 'novel'],\n",
       " 'afterwards': ['eyelid', 'considering', 'retinol', 'aesthetician', 'unboxed'],\n",
       " 'acne': ['endovenera', 'ksubi', 'covet', 'couture', 'mens']}"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from gensim.models import word2vec\n",
    "\n",
    "# tokenize sentences in corpus\n",
    "wpt = nltk.WordPunctTokenizer()\n",
    "tokenized_corpus = [wpt.tokenize(document) for document in corpus]\n",
    "\n",
    "# Set values for various parameters\n",
    "feature_size = 100    # Word vector dimensionality  \n",
    "window_context = 30          # Context window size                                                                                    \n",
    "min_word_count = 1   # Minimum word count                        \n",
    "sample = 1e-3   # Downsample setting for frequent words\n",
    "\n",
    "w2v_model = word2vec.Word2Vec(tokenized_corpus, size=feature_size, \n",
    "                          window=window_context, min_count=min_word_count,\n",
    "                          sample=sample, iter=50)\n",
    "\n",
    "# view similar words based on gensim's model\n",
    "similar_words = {search_term: [item[0] for item in w2v_model.wv.most_similar([search_term], topn=5)]\n",
    "                  for search_term in ['god', 'jesus', 'abundance', 'apache', 'abbreviate', 'anyway', 'afterwards','acne']}\n",
    "similar_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = w2v_model.wv.index2word\n",
    "wvs = w2v_model.wv[words]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seeing embedding of word 'applause'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-3.51967186e-01,  3.31496507e-01,  7.16749057e-02,  2.62756646e-01,\n",
       "       -7.60792494e-02,  4.53859568e-03,  1.65582612e-01, -1.01507850e-01,\n",
       "        8.01030457e-01, -5.64451158e-01, -6.51418388e-01, -8.39015722e-01,\n",
       "       -3.15783203e-01,  1.95099059e-02, -5.24626791e-01,  2.07230955e-01,\n",
       "        6.96181595e-01,  2.79045422e-02,  1.81374714e-01,  4.92202975e-02,\n",
       "        4.22733128e-01,  5.23031890e-01, -3.16612661e-01,  2.82642722e-01,\n",
       "       -1.63454413e-01, -4.32839185e-01, -4.57449585e-01,  1.89523876e-01,\n",
       "       -2.57522106e-01, -1.64460912e-01,  1.70660857e-02, -8.01335126e-02,\n",
       "       -1.69692248e-01,  1.26899064e-01,  1.98023306e-04, -2.14384854e-01,\n",
       "        7.57435784e-02, -5.19181371e-01, -4.74635243e-01, -4.30382729e-01,\n",
       "        1.70249328e-01, -6.52848482e-01, -2.79334098e-01, -2.94923425e-01,\n",
       "       -8.50626171e-01,  4.44952905e-01, -4.95493263e-01,  2.16606390e-02,\n",
       "        2.61651985e-02,  1.14026713e+00,  1.73267841e-01, -5.99691421e-02,\n",
       "        3.08364555e-02, -2.57661045e-01, -1.45973703e-02,  2.78595835e-01,\n",
       "        1.09669805e-01, -7.40144968e-01, -2.11777389e-01, -2.89901048e-01,\n",
       "       -3.78126085e-01, -4.90962148e-01,  4.44045924e-02, -1.01392172e-01,\n",
       "        6.15992546e-01, -7.02484012e-01, -1.57953247e-01,  3.89002562e-01,\n",
       "       -5.78660369e-01, -2.84568727e-01, -7.75598824e-01, -7.28835166e-02,\n",
       "        1.42068222e-01, -8.55436087e-01, -6.03633262e-02, -6.76942170e-01,\n",
       "        2.87903279e-01, -3.44615012e-01,  5.69222152e-01, -1.84907258e-01,\n",
       "       -1.35551021e-01, -7.23429859e-01,  5.39627016e-01, -3.78129371e-02,\n",
       "        1.04206905e-01,  2.62538582e-01,  7.24462450e-01,  1.54993594e-01,\n",
       "       -5.45016766e-01,  5.37445784e-01,  5.56451678e-01,  9.55364332e-02,\n",
       "       -2.09270552e-01,  2.40593016e-01, -5.50895706e-02,  6.28971100e-01,\n",
       "       -5.66803277e-01,  4.47421730e-01,  7.97443926e-01,  6.59780860e-01],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v_model.wv['applause']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GLove\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
